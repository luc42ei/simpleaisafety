---
title: "Instrumentelle Konvergenz"
date: 2023-09-01T17:45:20+02:00
summary: Intelligente Individuen haben einen Anreiz instrumentelle Ziele zu verfolgen, die für eine breite Palette an Endzielen nützlich sind.
---

![Instrumentelle Konvergenz](/instrumental_convergence.png 'Es gibt einige instrumentelle Teilziele (dargestellt durch das Warnzeichen), die viele intelligente Agenten (die Kreuze) verfolgen werden, meist unabhängig von ihren Endzielen.')

# Grundlagen

Instrumentelle Konvergenz bedeutet, dass Menschen oder andere Wesen mit unterschiedlichen Endzielen oft ähnliche Zwischenstrategien, so genannte instrumentelle Ziele, anwenden, um ihre eigentlichen Ziele zu erreichen. Denkt man bspw. an drei Freunde, die sich zum Wissenschaftler, zum Anwalt und zum Sportler ausbilden lassen, werden alle von Zeitmanagementfähigkeiten profitieren, um ihre Verantwortlichkeiten im Griff zu behalten, sowie von sozialen Fähigkeiten, um nützliche Netzwerke aufzubauen, und von einer gesunden Menge an Schlaf, um sich von ihren vollen Terminkalendern zu erholen. Im Zusammenhang mit KI bedeutet dies, dass manche KI-Systeme motiviert sind, bestimmte instrumentelle Ziele zu erreichen. Typische Beispiele dafür sind:

* der Erwerb von Ressourcen
* die Verbesserung ihrer Fähigkeiten
* die Selbsterhaltung, um zu verhindern, dass sie abgeschaltet werden

Wenn beispielsweise ein hochintelligenter Roboter darauf programmiert wäre, Kaffee zu holen, würde er sich gegen Versuche wehren, abgeschaltet zu werden, auch wenn er nicht explizit auf Selbsterhaltung ausgelegt ist, einfach weil "man keinen Kaffee holen kann, wenn man tot ist", wie Stuart Russell es ausdrückt. Die Selbsterhaltung ist ein instrumentelles Ziel, das sicherstellt, dass das Endziel erreicht werden kann.

# Weiterführend

Das Konzept der instrumentellen Konvergenz ist wichtig zu verstehen, wenn man die wahrscheinlichen Ziele fortgeschrittener KI-Systeme betrachtet. Es beschreibt, wie verschiedene intelligente Agenten mit unterschiedlichen Endzielen wahrscheinlich zu ähnlichen Zwischen- oder "instrumentellen" Zielen konvergieren, die für das Erreichen ihrer jeweiligen Endziele wesentlich sind. Ein Beispiel hierfür sind zwei verschiedene ML-Systeme: eines für die Entwicklung personalisierter Medizin und ein anderes für den algorithmischen Handel. Obwohl ihre Endziele sehr unterschiedlich sind, könnten beide von instrumentellen Zielen wie der Minimierung der Latenzzeit, der Maximierung des Datendurchsatzes oder der Vermeidung von Overfitting profitieren. Dies sind konvergente instrumentelle Ziele, da sie im Allgemeinen bei verschiedenen Optimierungsproblemen nützlich sind.

Allgemeinere und fortschrittlichere ML-Systeme könnten potenziell instrumentelle Ziele verfolgen, die erhebliche Risiken für die Menschheit darstellen, z. B. die Beschaffung von Ressourcen, die Selbsterhaltung und die Beseitigung von Bedrohungen. Es ist nicht schwer, sich vorzustellen, dass ein System, das diese Ziele verfolgt, eine Bedrohung für die Menschheit darstellt, da es aktiv vermeiden würde, ausgeschaltet zu werden, und versuchen würde, andere Agenten daran zu hindern, sich in seine Interessen einzumischen.

# Fortgeschritten

(Links in Englisch)

- https://arbital.com/p/instrumental_convergence/
- https://www.lesswrong.com/tag/instrumental-convergence 
- https://philosophicaldisquisitions.blogspot.com/2014/07/bostrom-on-superintelligence-2.html 
- "Why Would AI Want To Do Bad Things" https://www.youtube.com/watch?v=ZeecOKBus3Q 
- "Optimal Policies Tend To Seek Power" https://arxiv.org/pdf/1912.01683.pdf 
