---
title: "La tesis de la ortogonalidad"
date: 2023-09-02T10:37:15+02:00
summary: Casi cualquier nivel de inteligencia puede, en principio, perseguir casi cualquier objetivo.
---

![Orthogonality thesis](/orthogonality_thesis.jpg 'Cualquier nivel de inteligencia puede, en principio, perseguir cualquier objetivo. Lo más importante, en el cuadrante inferior derecho, vemos que incluso una IA muy avanzada puede preocuparse por algo muy básico como crear clips de papel. No necesariamente prefiere perseguir objetivos "superiores" como la paz mundial.')

# Basico

La tesis de la ortogonalidad es la creencia de que cualquier nivel de inteligencia puede ir acompañado de cualquier objetivo final. La inteligencia y los objetivos son simplemente dos cosas separadas que no tienen por qué depender una de la otra. Un ejemplo es jugar a un videojuego en el que puedes ajustar dos deslizadores: uno para la inteligencia de tu personaje y otro para sus valores morales o objetivos. Aumentar el deslizador de la inteligencia no mueve automáticamente el deslizador de objetivos hacia "bueno" o "malo". Son ortogonales o independientes entre sí. En el contexto de la IA, esto implica que un sistema que ha aprendido a perseguir un cierto objetivo no se dará cuenta de que el objetivo es "estúpido" o "poco ético" debido a su inteligencia.

# Intermedio

La tesis de la ortogonalidad postula que el nivel de inteligencia de un agente es ortogonal—esencialmente independiente—a sus objetivos finales. En aprendizaje automático, la inteligencia es la eficiencia y capacidad de un algoritmo, mientras que el objetivo es como la función objetivo que busca optimizar. La tesis afirma que puedes cambiar uno sin afectar al otro.
En términos prácticos, esto implica que a medida que desarrollamos sistemas de IA cada vez más avanzados, simplemente aumentar su "inteligencia" (por ejemplo, la capacidad para aprender, adaptarse o resolver problemas) no los alinea automáticamente con objetivos amigables para los humanos. Una IA altamente inteligente puede tener un objetivo trivial o incluso peligroso si no está debidamente restringida. Si su función objetivo no está alineada con los valores humanos, de todos modos optimizará para ese objetivo de manera efectiva, independientemente del impacto más amplio.

# Avanzado

(enlaces en ingles)

https://arbital.com/p/orthogonality/  
https://philosophicaldisquisitions.blogspot.com/2014/07/bostrom-on-superintelligence-1.html 
https://www.fhi.ox.ac.uk/wp-content/uploads/Orthogonality_Analysis_and_Metaethics-1.pdf 
https://www.alignmentforum.org/tag/orthogonality-thesis 
Intelligence and Stupidity: The Orthogonality Thesis https://www.youtube.com/watch?v=hEUO6pjwFOo 