# Basico

La convergencia instrumental significa que los humanos, u otras entidades, con diferentes objetivos finales a menudo adoptarán estrategias intermedias similares, conocidas como objetivos instrumentales, para ayudarles a alcanzar sus objetivos finales. Por ejemplo, tres amigos que se están formando para ser científico, abogado y atleta respectivamente, todos se beneficiarán de habilidades de gestión del tiempo para equilibrar sus responsabilidades, habilidades sociales para construir redes útiles y una cantidad saludable de sueño para recuperarse de sus apretadas agendas. En el contexto de la IA, esto implica que los sistemas de IA estarán motivados para alcanzar ciertos objetivos instrumentales, como la adquisición de recursos, capacidades mejoradas y, en última instancia, la autopreservación para evitar ser apagados. 

Por ejemplo, si un robot altamente inteligente fue programado para traer café, resistiría intentos de ser apagado a pesar de no haber sido diseñado para la autopreservación, simplemente porque "no puedes traer el café si estás muerto", como lo expresa Stuart Russell. La autopreservación es un objetivo instrumental que asegura que se pueda alcanzar el objetivo final.

# Intermedio

El concepto de convergencia instrumental es importante para entender cuando se consideran los objetivos probables de sistemas avanzados de IA. Describe cómo varios agentes inteligentes con diferentes objetivos finales probablemente convergerán en objetivos intermedios o "instrumentales" similares que son esenciales para alcanzar sus respectivos objetivos finales. Un ejemplo de esto son dos sistemas diferentes de aprendizaje automático (ML): uno diseñado para desarrollar medicina personalizada y otro para el comercio algorítmico. Aunque sus objetivos finales son muy diferentes, ambos podrían beneficiarse de objetivos instrumentales como minimizar la latencia, maximizar el rendimiento de datos o evitar el sobreajuste. Estos son objetivos instrumentales convergentes porque son generalmente útiles en diferentes problemas de optimización.

Sistemas de aprendizaje automático más generales y avanzados podrían compartir objetivos instrumentales que representan riesgos significativos para la humanidad, como la adquisición de recursos, la autopreservación y la eliminación de amenazas. No es difícil imaginar que un sistema que persiga estos objetivos constituiría una amenaza para la humanidad, ya que activamente evitaría ser apagado y buscaría prevenir que otros agentes interfieran en sus intereses.

# Avanzado

(enlaces en ingles)

- https://arbital.com/p/instrumental_convergence/
- https://www.lesswrong.com/tag/instrumental-convergence 
- https://philosophicaldisquisitions.blogspot.com/2014/07/bostrom-on-superintelligence-2.html 
- Why Would AI Want To Do Bad Things https://www.youtube.com/watch?v=ZeecOKBus3Q 
- Optimal Policies Tend To Seek Power https://arxiv.org/pdf/1912.01683.pdf 
